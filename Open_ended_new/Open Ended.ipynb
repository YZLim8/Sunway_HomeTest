{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fe4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('histoy_investment_results.csv')\n",
    "\n",
    "#Remove duplicated data\n",
    "df.duplicated().shape\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e96d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining Dependent Variable\n",
    "investment = df.drop('result', axis=1)\n",
    "investment_labels = df['result'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12e150",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation for numerical variables\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median') # using the median\n",
    "\n",
    "#Select the numerical varibles\n",
    "investment_num = investment.select_dtypes(include=[np.number])\n",
    "\n",
    "imputer.fit(investment_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8b613",
   "metadata": {},
   "source": [
    "### Handling categorical attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b558ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_cat = investment[['categorical data']]\n",
    "\n",
    "#Classify them to 1Hot & ordinal (0/1)\n",
    "investment_cat_oneHot = investment_cat[['1 hot categorical data']]\n",
    "investment_cat_ordinal = investment_cat[['ordinal categorical data']]\n",
    "\n",
    "#Changing them to 1Hot\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "investment_cat_1hot = cat_encoder.fit_transform(investment_cat_oneHot)\n",
    "\n",
    "#Change them to ordinal\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal = OrdinalEncoder()\n",
    "investment_ordinal_transform = ordinal.fit_transform(investment_cat_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f50195",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "#Standardization\n",
    "std_scaler = StandardScaler()\n",
    "investment_scaled = std_scaler.fit_transform(investment_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d61879",
   "metadata": {},
   "source": [
    "### Transformation Pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2414c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#1st - Imputation & Standardization\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "investment_prepared = num_pipeline.fit_transform(investment_num)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Classifying the variables\n",
    "num_features = ['list out all the numerical features']\n",
    "cat_features_1hot = ['list out all the 1 hot features']\n",
    "cat_features_ordinal = ['list out all the ordinal features']\n",
    "\n",
    "#2nd\n",
    "OneHot_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy='most_frequent')),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#3rd\n",
    "Ordinal_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"1hot\", OneHot_pipeline, cat_features_1hot),\n",
    "    (\"ordinal\", Ordinal_pipeline, cat_features_ordinal),\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy=\"minority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b31df8",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffc492",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39024a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = imbpipeline(steps = [\n",
    "    [\"preprocessing\", preprocessing],\n",
    "    [\"SMOTE\", SMOTE(random_state=0, sampling_strategy='minority')],\n",
    "    [\"logistic\", LogisticRegression(solver='lbfgs', random_state=0, penalty='l2')]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = investment\n",
    "Y = investment_labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c517566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "logReg.fit(X_train, Y_train)\n",
    "y_pred = logReg.predict(X_test)\n",
    "y_proba = logReg.decision_function(X_test)\n",
    "phat = y_proba\n",
    "decision_boundary = X_test[y_proba >= 0.5]\n",
    "\n",
    "print(\"\\n Logistic Regression Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#display the confusion matrix to visualize the result\n",
    "print(\"\\n Confusion matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6915088",
   "metadata": {},
   "source": [
    "### Random Search to fine tune the Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84fcbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param_grid={\n",
    "    'GBM__n_estimators':[100, 200, 300],\n",
    "    'GBM__learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = logReg, param_distributions = param_grid, n_iter = 50, cv = 5, scoring = 'f1', random_state = 0)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params_LR = random_search.best_params_\n",
    "\n",
    "print(best_params_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490cc08",
   "metadata": {},
   "source": [
    "### Super Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Initialize the SVM model\n",
    "svm = imbpipeline(steps=[\n",
    "    [\"preprocessing\", preprocessing],\n",
    "    [\"SMOTE\", SMOTE(random_state=0, sampling_strategy='minority')],\n",
    "    [\"SVM\", SVC(kernel='linear')]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3829cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = investment\n",
    "y = investment_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"\\n SVM Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n Confusion matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de28aff",
   "metadata": {},
   "source": [
    "### Random Search to fine tune the SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f708a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SVM = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'gamma':['scale', 'auto'],\n",
    "              'kernel': ['linear']}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = svm, param_distributions = param_grid_SVM, n_iter = 50, cv = 5, scoring = 'f1', random_state = 0)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params_SVM = random_search.best_params_\n",
    "\n",
    "print(best_params_SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e763d7c",
   "metadata": {},
   "source": [
    "### Neural Network Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "NNM = imbpipeline(steps = [\n",
    "    [\"preprocessing\", preprocessing],\n",
    "    [\"SMOTE\", SMOTE(random_state=0, sampling_strategy='minority')],\n",
    "    [\"NNM\", MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(10,), random_state=1)]\n",
    "])\n",
    "\n",
    "X = investment\n",
    "Y = investment_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.2, random_state=0)\n",
    "\n",
    "NNM.fit(X_train, y_train)\n",
    "y_pred = NNM.predict(X_test)\n",
    "\n",
    "print(\"\\n NNM Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n Confusion matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bbdb1",
   "metadata": {},
   "source": [
    "### Random Search to fine tune the NNM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'NNM__alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'NNM__hidden_layer_sizes': [(5,), (10,), (5, 2), (10, 5)],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = NNM, param_distributions = param_distributions, n_iter = 50, cv = 5, scoring = 'f1', random_state = 0)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params_NNM = random_search.best_params_\n",
    "\n",
    "print(best_params_NNM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c82fa3",
   "metadata": {},
   "source": [
    "### Select the best model with its best parameters to predict the result of new investments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the best model\n",
    "Best_model = imbpipeline(steps = [\n",
    "    [\"preprocessing\", preprocessing],\n",
    "    [\"SMOTE\", SMOTE(random_state=0, sampling_strategy='minority')],\n",
    "    [\"Best_model\",]\n",
    "])\n",
    "\n",
    "Best_model.fit(X, Y)\n",
    "\n",
    "df2 = pd.read_csv('new_investment_data')\n",
    "\n",
    "#Determining Dependent Variable\n",
    "new_investment = df2.drop('result', axis=1)\n",
    "\n",
    "y_pred_new = Best_model.predict(new_investment)\n",
    "\n",
    "print(\"Predicted outcomes for new investments suggestion:\")\n",
    "print(y_pred_new)\n",
    "\n",
    "#Visualize the result in a table\n",
    "new_investment['result'] = y_pred_new\n",
    "new_investment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
